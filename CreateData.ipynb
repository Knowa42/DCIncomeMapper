{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Step One: Collect the data\n",
    "\n",
    "I queried the Census Website's \"American Fact Finder\" for income data from the American Community Survey (ACS). You can find that data (for the District of Columbia) here: http://factfinder.census.gov/faces/tableservices/jsf/pages/productview.xhtml?pid=ACS_14_5YR_B19001&prodType=table\n",
    "\n",
    "I chose the option from the interface to download the table as a .csv file, which we load in to pandas right here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ACS_14_5YR_B19001_with_ann.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I show the first row of the data-frame (transposed for ease of viewing), which is a detailed name for each of the cryptic ACS column names. I'll use this for reference as I'm exploring the data, and will mention it several times in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GEO.id</th>\n",
       "      <td>Id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEO.id2</th>\n",
       "      <td>Id2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEO.display-label</th>\n",
       "      <td>Geography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD01</th>\n",
       "      <td>Estimate; Total:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD01</th>\n",
       "      <td>Margin of Error; Total:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD02</th>\n",
       "      <td>Estimate; Total: - Less than $10,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD02</th>\n",
       "      <td>Margin of Error; Total: - Less than $10,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD03</th>\n",
       "      <td>Estimate; Total: - $10,000 to $14,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD03</th>\n",
       "      <td>Margin of Error; Total: - $10,000 to $14,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD04</th>\n",
       "      <td>Estimate; Total: - $15,000 to $19,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD04</th>\n",
       "      <td>Margin of Error; Total: - $15,000 to $19,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD05</th>\n",
       "      <td>Estimate; Total: - $20,000 to $24,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD05</th>\n",
       "      <td>Margin of Error; Total: - $20,000 to $24,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD06</th>\n",
       "      <td>Estimate; Total: - $25,000 to $29,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD06</th>\n",
       "      <td>Margin of Error; Total: - $25,000 to $29,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD07</th>\n",
       "      <td>Estimate; Total: - $30,000 to $34,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD07</th>\n",
       "      <td>Margin of Error; Total: - $30,000 to $34,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD08</th>\n",
       "      <td>Estimate; Total: - $35,000 to $39,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD08</th>\n",
       "      <td>Margin of Error; Total: - $35,000 to $39,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD09</th>\n",
       "      <td>Estimate; Total: - $40,000 to $44,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD09</th>\n",
       "      <td>Margin of Error; Total: - $40,000 to $44,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD10</th>\n",
       "      <td>Estimate; Total: - $45,000 to $49,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD10</th>\n",
       "      <td>Margin of Error; Total: - $45,000 to $49,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD11</th>\n",
       "      <td>Estimate; Total: - $50,000 to $59,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD11</th>\n",
       "      <td>Margin of Error; Total: - $50,000 to $59,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD12</th>\n",
       "      <td>Estimate; Total: - $60,000 to $74,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD12</th>\n",
       "      <td>Margin of Error; Total: - $60,000 to $74,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD13</th>\n",
       "      <td>Estimate; Total: - $75,000 to $99,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD13</th>\n",
       "      <td>Margin of Error; Total: - $75,000 to $99,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD14</th>\n",
       "      <td>Estimate; Total: - $100,000 to $124,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD14</th>\n",
       "      <td>Margin of Error; Total: - $100,000 to $124,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD15</th>\n",
       "      <td>Estimate; Total: - $125,000 to $149,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD15</th>\n",
       "      <td>Margin of Error; Total: - $125,000 to $149,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD16</th>\n",
       "      <td>Estimate; Total: - $150,000 to $199,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD16</th>\n",
       "      <td>Margin of Error; Total: - $150,000 to $199,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD17</th>\n",
       "      <td>Estimate; Total: - $200,000 or more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD17</th>\n",
       "      <td>Margin of Error; Total: - $200,000 or more</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                0\n",
       "GEO.id                                                         Id\n",
       "GEO.id2                                                       Id2\n",
       "GEO.display-label                                       Geography\n",
       "HD01_VD01                                        Estimate; Total:\n",
       "HD02_VD01                                 Margin of Error; Total:\n",
       "HD01_VD02                    Estimate; Total: - Less than $10,000\n",
       "HD02_VD02             Margin of Error; Total: - Less than $10,000\n",
       "HD01_VD03                   Estimate; Total: - $10,000 to $14,999\n",
       "HD02_VD03            Margin of Error; Total: - $10,000 to $14,999\n",
       "HD01_VD04                   Estimate; Total: - $15,000 to $19,999\n",
       "HD02_VD04            Margin of Error; Total: - $15,000 to $19,999\n",
       "HD01_VD05                   Estimate; Total: - $20,000 to $24,999\n",
       "HD02_VD05            Margin of Error; Total: - $20,000 to $24,999\n",
       "HD01_VD06                   Estimate; Total: - $25,000 to $29,999\n",
       "HD02_VD06            Margin of Error; Total: - $25,000 to $29,999\n",
       "HD01_VD07                   Estimate; Total: - $30,000 to $34,999\n",
       "HD02_VD07            Margin of Error; Total: - $30,000 to $34,999\n",
       "HD01_VD08                   Estimate; Total: - $35,000 to $39,999\n",
       "HD02_VD08            Margin of Error; Total: - $35,000 to $39,999\n",
       "HD01_VD09                   Estimate; Total: - $40,000 to $44,999\n",
       "HD02_VD09            Margin of Error; Total: - $40,000 to $44,999\n",
       "HD01_VD10                   Estimate; Total: - $45,000 to $49,999\n",
       "HD02_VD10            Margin of Error; Total: - $45,000 to $49,999\n",
       "HD01_VD11                   Estimate; Total: - $50,000 to $59,999\n",
       "HD02_VD11            Margin of Error; Total: - $50,000 to $59,999\n",
       "HD01_VD12                   Estimate; Total: - $60,000 to $74,999\n",
       "HD02_VD12            Margin of Error; Total: - $60,000 to $74,999\n",
       "HD01_VD13                   Estimate; Total: - $75,000 to $99,999\n",
       "HD02_VD13            Margin of Error; Total: - $75,000 to $99,999\n",
       "HD01_VD14                 Estimate; Total: - $100,000 to $124,999\n",
       "HD02_VD14          Margin of Error; Total: - $100,000 to $124,999\n",
       "HD01_VD15                 Estimate; Total: - $125,000 to $149,999\n",
       "HD02_VD15          Margin of Error; Total: - $125,000 to $149,999\n",
       "HD01_VD16                 Estimate; Total: - $150,000 to $199,999\n",
       "HD02_VD16          Margin of Error; Total: - $150,000 to $199,999\n",
       "HD01_VD17                     Estimate; Total: - $200,000 or more\n",
       "HD02_VD17              Margin of Error; Total: - $200,000 or more"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I drop the first row of the dataframe, which will not be useful as I actually begin to perform actions on the data. On the line after I drop the row, I call ```df.head()``` to ensure that the row is gone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GEO.id</th>\n",
       "      <td>1500000US110010001001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEO.id2</th>\n",
       "      <td>110010001001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEO.display-label</th>\n",
       "      <td>Block Group 1, Census Tract 1, District of Col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD01</th>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD01</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD02</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD02</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD03</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD03</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD04</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD04</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD05</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD05</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD06</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD06</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD07</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD07</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD08</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD08</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD09</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD09</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD10</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD10</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD11</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD11</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD12</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD12</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD13</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD13</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD14</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD14</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD15</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD15</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD16</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD16</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD01_VD17</th>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD02_VD17</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   1\n",
       "GEO.id                                         1500000US110010001001\n",
       "GEO.id2                                                 110010001001\n",
       "GEO.display-label  Block Group 1, Census Tract 1, District of Col...\n",
       "HD01_VD01                                                        641\n",
       "HD02_VD01                                                        104\n",
       "HD01_VD02                                                         25\n",
       "HD02_VD02                                                         40\n",
       "HD01_VD03                                                         20\n",
       "HD02_VD03                                                         31\n",
       "HD01_VD04                                                          0\n",
       "HD02_VD04                                                         12\n",
       "HD01_VD05                                                         22\n",
       "HD02_VD05                                                         32\n",
       "HD01_VD06                                                          0\n",
       "HD02_VD06                                                         12\n",
       "HD01_VD07                                                          0\n",
       "HD02_VD07                                                         12\n",
       "HD01_VD08                                                         13\n",
       "HD02_VD08                                                         21\n",
       "HD01_VD09                                                         15\n",
       "HD02_VD09                                                         24\n",
       "HD01_VD10                                                          0\n",
       "HD02_VD10                                                         12\n",
       "HD01_VD11                                                         34\n",
       "HD02_VD11                                                         37\n",
       "HD01_VD12                                                         36\n",
       "HD02_VD12                                                         43\n",
       "HD01_VD13                                                         37\n",
       "HD02_VD13                                                         42\n",
       "HD01_VD14                                                         77\n",
       "HD02_VD14                                                         55\n",
       "HD01_VD15                                                         43\n",
       "HD02_VD15                                                         34\n",
       "HD01_VD16                                                         42\n",
       "HD02_VD16                                                         38\n",
       "HD01_VD17                                                        277\n",
       "HD02_VD17                                                         91"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, it worked! Now, lets find out some information about our data-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267415"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.HD01_VD01.astype(int).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of data-points collected in this survey was apparently 267,415. I arrived at that number by finding the sum of the cells in the HD01_VD01 column which, according to the detailed column-names row from code-block 3 of this notebook, is the total-population surveyed in this particular years ACS. This is useful to know because when we finally move on to mapping this data, THAT will be the number of points we should see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speaking of mapping, now is a great time to explain how the Census Bureau breaks down the country into geo-spatial sections. This is essential knowledge for anybody who wants to visualize census data on a map! In short, the Census Buraeu breaks down each of the 50 stats (as well as Puerto Rico and The District of Columbia) into six additional subgroups. Those subgroups, in ascending degree of specificitiy, are County -> County Subdivision -> Place -> Place Part -> Census Tract -> Block Group -> Block, where states are made of counties, which are made of county subdivions... you see where this is going. In the style of a directory hierarchy, these groups would look like this:\n",
    "\n",
    "    |State  \n",
    "    |-->County\n",
    "    |   |-->County Subdivision\n",
    "    |   |   |-->Place\n",
    "    |   |   |   |-->Place Part\n",
    "    |   |   |   |   |-->Census Tract\n",
    "    |   |   |   |   |   |-->Block Group\n",
    "    |   |   |   |   |   |   |-->Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the lesson pn Census organization techinqiues is over, it's time to get back to the data... which brings up a common problem-- we need more of it! The data in the .csv than I downloaded from American Factfinder separates data based on block-group, but I currently have no way to associate those block-groups with coordinates on a map. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, TIGER shapefiles exist! TIGER stands for 'Topilogically Integrated Geographic Encoding and Referencing', and a TIGER product is exactly what we need right now.  We can find a .shp file for Washington, D.C. block-groups at http://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2015&layergroup=Block+Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be using several libraries to work with this .shp file. First, I use `ogr` from `osgeo` to load in the .shp file. I also import certain shapely functions for working with individual polygons within the .shp file (but more on that later!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from osgeo import ogr\n",
    "from shapely.wkb import loads\n",
    "from shapely.geometry import *\n",
    "from random import uniform\n",
    "\n",
    "from globalmaptiles import GlobalMercator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll also see that I importet from a library called globalmaptiles. I need the GlobalMercator class because, in order to visualize the data using the tool I want to use (DataShader), I need to project geodetic coordinates as WebMercator. This class allows me to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a GlobalMercator object for later conversions    \n",
    "merc = GlobalMercator()\n",
    "\n",
    "# Open .shp file downloaded from TIGER\n",
    "ds = ogr.Open(r\"/home/terminal/projects/tl_2014_11_bg.shp\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE:** In order to load this .shp file using ogr, you need to have all files extracted from the .zip that you downloaded from TIGER in the same directory. I don't know why, but that's how it's gotta be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Two: Transform data into a form that can be mapped using DataShader. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section of the notebook, I will be *heavily* borrowing from the fantastic code written by unorthodox123 in their RacialDotMap repository on GitHub. [Their racial dot map](http://demographics.coopercenter.org/DotMap/index.html)  was part of the inspiration for me creating the visualization that I'm working towards in this notebook. You can find this repository [here](https://github.com/unorthodox123/RacialDotMap)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, I'm going to get a ogr.Layer object from the .shp file we loaded using ogr, then save it to the variable `lyr`. After that, I call `lyr.ResetReading()` to reset the object to the first feature in the layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, the code uses `lyr.GetLayerDefn()` to get the scheme information for the layer. It then uses that information to create a list of each field in the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " # Obtain the first (and only) layer in the shapefile\n",
    "lyr = ds.GetLayerByIndex(0)\n",
    "\n",
    "lyr.ResetReading()\n",
    "\n",
    "# Obtain the field definitions in the shapefile layer\n",
    "\n",
    "feat_defn = lyr.GetLayerDefn()\n",
    "field_defns = [feat_defn.GetFieldDefn(i) for i in range(feat_defn.GetFieldCount())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I loop through `field_defns` in order to get the index for `'GEOID'`. I need this in order to correlate block-groups from my ACS data with block-group polygons from my TIGER data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Obtain the index of the field for the count for GEOID\n",
    "\n",
    "for i, defn in enumerate(field_defns):\n",
    "    if defn.GetName() == 'GEOID':\n",
    "        geo_field = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up next comes the real heavy-lifting of this notebook. It's a long (un-refactored or optimized) block of code, so I'll explain here what it's doing.\n",
    "\n",
    "Basically, my end goal is to create a geospatial representation of income data for Washington, D.C.. I have data organized for each block-group in D.C., but simply shading in a polygon isn't good enough for me. Therefore, I'm going to randomly distribute a number of points (within each TIGER polygon) equal to the number of points for each income-bracket listed in our ACS dataframe. I'm going to save these points in a pandas dataframe that will eventually be exported into a .csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_features = len(lyr)\n",
    "out_csv = pd.DataFrame(columns=('GEO.id2', 'x', 'y', 'quadkey', 'income_category'))\n",
    "for j, feat in enumerate( lyr ):\n",
    "\n",
    "    # Print a progress read-out for every 10 features\n",
    "\n",
    "    if j % 10 == 0:\n",
    "        print(\"{0}/{1}\".format(j+1,n_features))\n",
    "        print(out_csv.count())\n",
    "\n",
    "    # Obtain total population and income bracket count for each block group\n",
    "    geo = feat.GetField(geo_field)\n",
    "    total_pop = int(df[df['GEO.id2'] == geo].HD01_VD01)\n",
    "    lt_10k = int(df[df['GEO.id2'] == geo].HD01_VD02)\n",
    "    bt_10k_15k = int(df[df['GEO.id2'] == geo].HD01_VD03)\n",
    "    bt_15k_20k = int(df[df['GEO.id2'] == geo].HD01_VD04)\n",
    "    bt_20k_25k = int(df[df['GEO.id2'] == geo].HD01_VD05)\n",
    "    bt_25k_30k = int(df[df['GEO.id2'] == geo].HD01_VD06)\n",
    "    bt_30k_35k = int(df[df['GEO.id2'] == geo].HD01_VD07)\n",
    "    bt_35k_40k = int(df[df['GEO.id2'] == geo].HD01_VD08)\n",
    "    bt_40k_45k = int(df[df['GEO.id2'] == geo].HD01_VD09)\n",
    "    bt_45k_50k = int(df[df['GEO.id2'] == geo].HD01_VD10)\n",
    "    bt_50k_60k = int(df[df['GEO.id2'] == geo].HD01_VD11)\n",
    "    bt_60k_75k = int(df[df['GEO.id2'] == geo].HD01_VD12)\n",
    "    bt_75k_100k = int(df[df['GEO.id2'] == geo].HD01_VD13)\n",
    "    bt_100k_125k = int(df[df['GEO.id2'] == geo].HD01_VD14)\n",
    "    bt_125k_150k = int(df[df['GEO.id2'] == geo].HD01_VD15)\n",
    "    bt_150k_200k = int(df[df['GEO.id2'] == geo].HD01_VD16)\n",
    "    gt_200k = int(df[df['GEO.id2'] == geo].HD01_VD17)\n",
    "\n",
    "    # Obtain the OGR polygon object from the feature\n",
    "\n",
    "    geom = feat.GetGeometryRef()\n",
    "\n",
    "    if geom is None:\n",
    "        print(\"continued\")\n",
    "        continue\n",
    "\n",
    "    # Convert the OGR Polygon into a Shapely Polygon\n",
    "\n",
    "    poly = loads(geom.ExportToWkb())\n",
    "\n",
    "    if poly is None:\n",
    "        continue\n",
    "    bbox = poly.bounds\n",
    "\n",
    "    if not bbox:\n",
    "        continue\n",
    "\n",
    "    leftmost,bottommost,rightmost,topmost = bbox\n",
    "    \n",
    "    # Generate a point object within the census block for every person by income category   \n",
    "    for i in range(lt_10k):\n",
    "                \n",
    "        # Choose a random longitude and latitude within the boundary box\n",
    "        # and within the orginial ploygon of the census block\n",
    "\n",
    "        while True:\n",
    "\n",
    "            samplepoint = Point(uniform(leftmost, rightmost),uniform(bottommost, topmost))\n",
    "\n",
    "            if samplepoint is None:\n",
    "                break\n",
    "\n",
    "            if poly.contains(samplepoint):\n",
    "                break\n",
    "\n",
    "        # Convert the longitude and latitude coordinates to meters and\n",
    "        # a tile reference\n",
    "\n",
    "        x, y = merc.LatLonToMeters(samplepoint.y,samplepoint.x)\n",
    "        tx,ty = merc.MetersToTile(x, y, 21)\n",
    "\n",
    "        # Create a unique quadkey for each point object\n",
    "                \n",
    "        quadkey = merc.QuadTree(tx, ty, 21)\n",
    "\n",
    "        # Create categorical variable for the income category\n",
    "\n",
    "        income_category = 'HD01_VD02'         \n",
    "\n",
    "        # Append data to dataframe\n",
    "        out_csv = out_csv.append(dict([('GEO.id2',geo),\n",
    "                                       ('x',x),\n",
    "                                       ('y',y),\n",
    "                                       ('quadkey',quadkey),\n",
    "                                       ('income_category',income_category)]),\n",
    "                                 ignore_index=True)\n",
    "        \n",
    "    for i in range(bt_10k_15k):\n",
    "                \n",
    "        # Choose a random longitude and latitude within the boundary box\n",
    "        # and within the orginial ploygon of the census block\n",
    "\n",
    "        while True:\n",
    "\n",
    "            samplepoint = Point(uniform(leftmost, rightmost),uniform(bottommost, topmost))\n",
    "\n",
    "            if samplepoint is None:\n",
    "                break\n",
    "\n",
    "            if poly.contains(samplepoint):\n",
    "                break\n",
    "\n",
    "        # Convert the longitude and latitude coordinates to meters and\n",
    "        # a tile reference\n",
    "\n",
    "        x, y = merc.LatLonToMeters(samplepoint.y,samplepoint.x)\n",
    "        tx,ty = merc.MetersToTile(x, y, 21)\n",
    "\n",
    "        # Create a unique quadkey for each point object\n",
    "                \n",
    "        quadkey = merc.QuadTree(tx, ty, 21)\n",
    "\n",
    "        # Create categorical variable for the income category\n",
    "\n",
    "        income_category = 'HD01_VD03'         \n",
    "\n",
    "        # Append data to dataframe\n",
    "        out_csv = out_csv.append(dict([('GEO.id2',geo),\n",
    "                                       ('x',x),\n",
    "                                       ('y',y),\n",
    "                                       ('quadkey',quadkey),\n",
    "                                       ('income_category',income_category)]),\n",
    "                                 ignore_index=True)\n",
    "        \n",
    "    for i in range(bt_15k_20k):\n",
    "                \n",
    "        # Choose a random longitude and latitude within the boundary box\n",
    "        # and within the orginial ploygon of the census block\n",
    "\n",
    "        while True:\n",
    "\n",
    "            samplepoint = Point(uniform(leftmost, rightmost),uniform(bottommost, topmost))\n",
    "\n",
    "            if samplepoint is None:\n",
    "                break\n",
    "\n",
    "            if poly.contains(samplepoint):\n",
    "                break\n",
    "\n",
    "        # Convert the longitude and latitude coordinates to meters and\n",
    "        # a tile reference\n",
    "\n",
    "        x, y = merc.LatLonToMeters(samplepoint.y,samplepoint.x)\n",
    "        tx,ty = merc.MetersToTile(x, y, 21)\n",
    "\n",
    "        # Create a unique quadkey for each point object\n",
    "                \n",
    "        quadkey = merc.QuadTree(tx, ty, 21)\n",
    "\n",
    "        # Create categorical variable for the income category\n",
    "\n",
    "        income_category = 'HD01_VD04'         \n",
    "\n",
    "        # Append data to dataframe\n",
    "\n",
    "        out_csv = out_csv.append(dict([('GEO.id2',geo),\n",
    "                                       ('x',x),\n",
    "                                       ('y',y),\n",
    "                                       ('quadkey',quadkey),\n",
    "                                       ('income_category',income_category)]),\n",
    "                                 ignore_index=True)\n",
    "        \n",
    "    for i in range(bt_20k_25k):\n",
    "                \n",
    "        # Choose a random longitude and latitude within the boundary box\n",
    "        # and within the orginial ploygon of the census block\n",
    "\n",
    "        while True:\n",
    "\n",
    "            samplepoint = Point(uniform(leftmost, rightmost),uniform(bottommost, topmost))\n",
    "\n",
    "            if samplepoint is None:\n",
    "                break\n",
    "\n",
    "            if poly.contains(samplepoint):\n",
    "                break\n",
    "\n",
    "        # Convert the longitude and latitude coordinates to meters and\n",
    "        # a tile reference\n",
    "\n",
    "        x, y = merc.LatLonToMeters(samplepoint.y,samplepoint.x)\n",
    "        tx,ty = merc.MetersToTile(x, y, 21)\n",
    "\n",
    "        # Create a unique quadkey for each point object\n",
    "                \n",
    "        quadkey = merc.QuadTree(tx, ty, 21)\n",
    "\n",
    "        # Create categorical variable for the income category\n",
    "\n",
    "        income_category = 'HD01_VD05'         \n",
    "\n",
    "        # Append data to dataframe\n",
    "        out_csv = out_csv.append(dict([('GEO.id2',geo),\n",
    "                                       ('x',x),\n",
    "                                       ('y',y),\n",
    "                                       ('quadkey',quadkey),\n",
    "                                       ('income_category',income_category)]),\n",
    "                                 ignore_index=True)\n",
    "        \n",
    "    for i in range(bt_25k_30k):\n",
    "                \n",
    "        # Choose a random longitude and latitude within the boundary box\n",
    "        # and within the orginial ploygon of the census block\n",
    "\n",
    "        while True:\n",
    "\n",
    "            samplepoint = Point(uniform(leftmost, rightmost),uniform(bottommost, topmost))\n",
    "\n",
    "            if samplepoint is None:\n",
    "                break\n",
    "\n",
    "            if poly.contains(samplepoint):\n",
    "                break\n",
    "\n",
    "        # Convert the longitude and latitude coordinates to meters and\n",
    "        # a tile reference\n",
    "\n",
    "        x, y = merc.LatLonToMeters(samplepoint.y,samplepoint.x)\n",
    "        tx,ty = merc.MetersToTile(x, y, 21)\n",
    "\n",
    "        # Create a unique quadkey for each point object\n",
    "                \n",
    "        quadkey = merc.QuadTree(tx, ty, 21)\n",
    "\n",
    "        # Create categorical variable for the income category\n",
    "\n",
    "        income_category = 'HD01_VD06'         \n",
    "\n",
    "        # Append data to dataframe\n",
    "        out_csv = out_csv.append(dict([('GEO.id2',geo),\n",
    "                                       ('x',x),\n",
    "                                       ('y',y),\n",
    "                                       ('quadkey',quadkey),\n",
    "                                       ('income_category',income_category)]),\n",
    "                                 ignore_index=True)\n",
    "        \n",
    "    for i in range(bt_30k_35k):\n",
    "                \n",
    "        # Choose a random longitude and latitude within the boundary box\n",
    "        # and within the orginial ploygon of the census block\n",
    "\n",
    "        while True:\n",
    "\n",
    "            samplepoint = Point(uniform(leftmost, rightmost),uniform(bottommost, topmost))\n",
    "\n",
    "            if samplepoint is None:\n",
    "                break\n",
    "\n",
    "            if poly.contains(samplepoint):\n",
    "                break\n",
    "\n",
    "        # Convert the longitude and latitude coordinates to meters and\n",
    "        # a tile reference\n",
    "\n",
    "        x, y = merc.LatLonToMeters(samplepoint.y,samplepoint.x)\n",
    "        tx,ty = merc.MetersToTile(x, y, 21)\n",
    "\n",
    "        # Create a unique quadkey for each point object\n",
    "                \n",
    "        quadkey = merc.QuadTree(tx, ty, 21)\n",
    "\n",
    "        # Create categorical variable for the income category\n",
    "\n",
    "        income_category = 'HD01_VD07'         \n",
    "\n",
    "        # Append data to dataframe\n",
    "        out_csv = out_csv.append(dict([('GEO.id2',geo),\n",
    "                                       ('x',x),\n",
    "                                       ('y',y),\n",
    "                                       ('quadkey',quadkey),\n",
    "                                       ('income_category',income_category)]),\n",
    "                                 ignore_index=True)\n",
    "        \n",
    "    for i in range(bt_35k_40k):\n",
    "                \n",
    "        # Choose a random longitude and latitude within the boundary box\n",
    "        # and within the orginial ploygon of the census block\n",
    "\n",
    "        while True:\n",
    "\n",
    "            samplepoint = Point(uniform(leftmost, rightmost),uniform(bottommost, topmost))\n",
    "\n",
    "            if samplepoint is None:\n",
    "                break\n",
    "\n",
    "            if poly.contains(samplepoint):\n",
    "                break\n",
    "\n",
    "        # Convert the longitude and latitude coordinates to meters and\n",
    "        # a tile reference\n",
    "\n",
    "        x, y = merc.LatLonToMeters(samplepoint.y,samplepoint.x)\n",
    "        tx,ty = merc.MetersToTile(x, y, 21)\n",
    "\n",
    "        # Create a unique quadkey for each point object\n",
    "                \n",
    "        quadkey = merc.QuadTree(tx, ty, 21)\n",
    "\n",
    "        # Create categorical variable for the income category\n",
    "\n",
    "        income_category = 'HD01_VD08'         \n",
    "\n",
    "        # Append data to dataframe\n",
    "        out_csv = out_csv.append(dict([('GEO.id2',geo),\n",
    "                                       ('x',x),\n",
    "                                       ('y',y),\n",
    "                                       ('quadkey',quadkey),\n",
    "                                       ('income_category',income_category)]),\n",
    "                                 ignore_index=True)\n",
    "        \n",
    "    for i in range(bt_40k_45k):\n",
    "                \n",
    "        # Choose a random longitude and latitude within the boundary box\n",
    "        # and within the orginial ploygon of the census block\n",
    "\n",
    "        while True:\n",
    "\n",
    "            samplepoint = Point(uniform(leftmost, rightmost),uniform(bottommost, topmost))\n",
    "\n",
    "            if samplepoint is None:\n",
    "                break\n",
    "\n",
    "            if poly.contains(samplepoint):\n",
    "                break\n",
    "\n",
    "        # Convert the longitude and latitude coordinates to meters and\n",
    "        # a tile reference\n",
    "\n",
    "        x, y = merc.LatLonToMeters(samplepoint.y,samplepoint.x)\n",
    "        tx,ty = merc.MetersToTile(x, y, 21)\n",
    "\n",
    "        # Create a unique quadkey for each point object\n",
    "                \n",
    "        quadkey = merc.QuadTree(tx, ty, 21)\n",
    "\n",
    "        # Create categorical variable for the income category\n",
    "\n",
    "        income_category = 'HD01_VD09'         \n",
    "\n",
    "        # Append data to dataframe\n",
    "        out_csv = out_csv.append(dict([('GEO.id2',geo),\n",
    "                                       ('x',x),\n",
    "                                       ('y',y),\n",
    "                                       ('quadkey',quadkey),\n",
    "                                       ('income_category',income_category)]),\n",
    "                                 ignore_index=True)\n",
    "        \n",
    "    for i in range(bt_45k_50k):\n",
    "                \n",
    "        # Choose a random longitude and latitude within the boundary box\n",
    "        # and within the orginial ploygon of the census block\n",
    "\n",
    "        while True:\n",
    "\n",
    "            samplepoint = Point(uniform(leftmost, rightmost),uniform(bottommost, topmost))\n",
    "\n",
    "            if samplepoint is None:\n",
    "                break\n",
    "\n",
    "            if poly.contains(samplepoint):\n",
    "                break\n",
    "\n",
    "        # Convert the longitude and latitude coordinates to meters and\n",
    "        # a tile reference\n",
    "\n",
    "        x, y = merc.LatLonToMeters(samplepoint.y,samplepoint.x)\n",
    "        tx,ty = merc.MetersToTile(x, y, 21)\n",
    "\n",
    "        # Create a unique quadkey for each point object\n",
    "                \n",
    "        quadkey = merc.QuadTree(tx, ty, 21)\n",
    "\n",
    "        # Create categorical variable for the income category\n",
    "\n",
    "        income_category = 'HD01_VD10'         \n",
    "\n",
    "        # Append data to dataframe\n",
    "        out_csv = out_csv.append(dict([('GEO.id2',geo),\n",
    "                                       ('x',x),\n",
    "                                       ('y',y),\n",
    "                                       ('quadkey',quadkey),\n",
    "                                       ('income_category',income_category)]),\n",
    "                                 ignore_index=True)\n",
    "        \n",
    "    for i in range(bt_50k_60k):\n",
    "                \n",
    "        # Choose a random longitude and latitude within the boundary box\n",
    "        # and within the orginial ploygon of the census block\n",
    "\n",
    "        while True:\n",
    "\n",
    "            samplepoint = Point(uniform(leftmost, rightmost),uniform(bottommost, topmost))\n",
    "\n",
    "            if samplepoint is None:\n",
    "                break\n",
    "\n",
    "            if poly.contains(samplepoint):\n",
    "                break\n",
    "\n",
    "        # Convert the longitude and latitude coordinates to meters and\n",
    "        # a tile reference\n",
    "\n",
    "        x, y = merc.LatLonToMeters(samplepoint.y,samplepoint.x)\n",
    "        tx,ty = merc.MetersToTile(x, y, 21)\n",
    "\n",
    "        # Create a unique quadkey for each point object\n",
    "                \n",
    "        quadkey = merc.QuadTree(tx, ty, 21)\n",
    "\n",
    "        # Create categorical variable for the income category\n",
    "\n",
    "        income_category = 'HD01_VD11'         \n",
    "\n",
    "        # Append data to dataframe\n",
    "        out_csv = out_csv.append(dict([('GEO.id2',geo),\n",
    "                                       ('x',x),\n",
    "                                       ('y',y),\n",
    "                                       ('quadkey',quadkey),\n",
    "                                       ('income_category',income_category)]),\n",
    "                                 ignore_index=True)\n",
    "        \n",
    "    for i in range(bt_60k_75k):\n",
    "                \n",
    "        # Choose a random longitude and latitude within the boundary box\n",
    "        # and within the orginial ploygon of the census block\n",
    "\n",
    "        while True:\n",
    "\n",
    "            samplepoint = Point(uniform(leftmost, rightmost),uniform(bottommost, topmost))\n",
    "\n",
    "            if samplepoint is None:\n",
    "                break\n",
    "\n",
    "            if poly.contains(samplepoint):\n",
    "                break\n",
    "\n",
    "        # Convert the longitude and latitude coordinates to meters and\n",
    "        # a tile reference\n",
    "\n",
    "        x, y = merc.LatLonToMeters(samplepoint.y,samplepoint.x)\n",
    "        tx,ty = merc.MetersToTile(x, y, 21)\n",
    "\n",
    "        # Create a unique quadkey for each point object\n",
    "                \n",
    "        quadkey = merc.QuadTree(tx, ty, 21)\n",
    "\n",
    "        # Create categorical variable for the income category\n",
    "\n",
    "        income_category = 'HD01_VD12'         \n",
    "\n",
    "        # Append data to dataframe\n",
    "        out_csv = out_csv.append(dict([('GEO.id2',geo),\n",
    "                                       ('x',x),\n",
    "                                       ('y',y),\n",
    "                                       ('quadkey',quadkey),\n",
    "                                       ('income_category',income_category)]),\n",
    "                                 ignore_index=True)\n",
    "        \n",
    "    for i in range(bt_75k_100k):\n",
    "                \n",
    "        # Choose a random longitude and latitude within the boundary box\n",
    "        # and within the orginial ploygon of the census block\n",
    "\n",
    "        while True:\n",
    "\n",
    "            samplepoint = Point(uniform(leftmost, rightmost),uniform(bottommost, topmost))\n",
    "\n",
    "            if samplepoint is None:\n",
    "                break\n",
    "\n",
    "            if poly.contains(samplepoint):\n",
    "                break\n",
    "\n",
    "        # Convert the longitude and latitude coordinates to meters and\n",
    "        # a tile reference\n",
    "\n",
    "        x, y = merc.LatLonToMeters(samplepoint.y,samplepoint.x)\n",
    "        tx,ty = merc.MetersToTile(x, y, 21)\n",
    "\n",
    "        # Create a unique quadkey for each point object\n",
    "                \n",
    "        quadkey = merc.QuadTree(tx, ty, 21)\n",
    "\n",
    "        # Create categorical variable for the income category\n",
    "\n",
    "        income_category = 'HD01_VD13'         \n",
    "\n",
    "        # Append data to dataframe\n",
    "        out_csv = out_csv.append(dict([('GEO.id2',geo),\n",
    "                                       ('x',x),\n",
    "                                       ('y',y),\n",
    "                                       ('quadkey',quadkey),\n",
    "                                       ('income_category',income_category)]),\n",
    "                                 ignore_index=True)\n",
    "        \n",
    "    for i in range(bt_100k_125k):\n",
    "                \n",
    "        # Choose a random longitude and latitude within the boundary box\n",
    "        # and within the orginial ploygon of the census block\n",
    "\n",
    "        while True:\n",
    "\n",
    "            samplepoint = Point(uniform(leftmost, rightmost),uniform(bottommost, topmost))\n",
    "\n",
    "            if samplepoint is None:\n",
    "                break\n",
    "\n",
    "            if poly.contains(samplepoint):\n",
    "                break\n",
    "\n",
    "        # Convert the longitude and latitude coordinates to meters and\n",
    "        # a tile reference\n",
    "\n",
    "        x, y = merc.LatLonToMeters(samplepoint.y,samplepoint.x)\n",
    "        tx,ty = merc.MetersToTile(x, y, 21)\n",
    "\n",
    "        # Create a unique quadkey for each point object\n",
    "                \n",
    "        quadkey = merc.QuadTree(tx, ty, 21)\n",
    "\n",
    "        # Create categorical variable for the income category\n",
    "\n",
    "        income_category = 'HD01_VD14'         \n",
    "\n",
    "        # Append data to dataframe\n",
    "        out_csv = out_csv.append(dict([('GEO.id2',geo),\n",
    "                                       ('x',x),\n",
    "                                       ('y',y),\n",
    "                                       ('quadkey',quadkey),\n",
    "                                       ('income_category',income_category)]),\n",
    "                                 ignore_index=True)\n",
    "        \n",
    "    for i in range(bt_125k_150k):\n",
    "                \n",
    "        # Choose a random longitude and latitude within the boundary box\n",
    "        # and within the orginial ploygon of the census block\n",
    "\n",
    "        while True:\n",
    "\n",
    "            samplepoint = Point(uniform(leftmost, rightmost),uniform(bottommost, topmost))\n",
    "\n",
    "            if samplepoint is None:\n",
    "                break\n",
    "\n",
    "            if poly.contains(samplepoint):\n",
    "                break\n",
    "\n",
    "        # Convert the longitude and latitude coordinates to meters and\n",
    "        # a tile reference\n",
    "\n",
    "        x, y = merc.LatLonToMeters(samplepoint.y,samplepoint.x)\n",
    "        tx,ty = merc.MetersToTile(x, y, 21)\n",
    "\n",
    "        # Create a unique quadkey for each point object\n",
    "                \n",
    "        quadkey = merc.QuadTree(tx, ty, 21)\n",
    "\n",
    "        # Create categorical variable for the income category\n",
    "\n",
    "        income_category = 'HD01_VD15'         \n",
    "\n",
    "        # Append data to dataframe\n",
    "        out_csv = out_csv.append(dict([('GEO.id2',geo),\n",
    "                                       ('x',x),\n",
    "                                       ('y',y),\n",
    "                                       ('quadkey',quadkey),\n",
    "                                       ('income_category',income_category)]),\n",
    "                                 ignore_index=True)\n",
    "        \n",
    "    for i in range(bt_150k_200k):\n",
    "                \n",
    "        # Choose a random longitude and latitude within the boundary box\n",
    "        # and within the orginial ploygon of the census block\n",
    "\n",
    "        while True:\n",
    "\n",
    "            samplepoint = Point(uniform(leftmost, rightmost),uniform(bottommost, topmost))\n",
    "\n",
    "            if samplepoint is None:\n",
    "                break\n",
    "\n",
    "            if poly.contains(samplepoint):\n",
    "                break\n",
    "\n",
    "        # Convert the longitude and latitude coordinates to meters and\n",
    "        # a tile reference\n",
    "\n",
    "        x, y = merc.LatLonToMeters(samplepoint.y,samplepoint.x)\n",
    "        tx,ty = merc.MetersToTile(x, y, 21)\n",
    "\n",
    "        # Create a unique quadkey for each point object\n",
    "                \n",
    "        quadkey = merc.QuadTree(tx, ty, 21)\n",
    "\n",
    "        # Create categorical variable for the income category\n",
    "\n",
    "        income_category = 'HD01_VD16'         \n",
    "\n",
    "        # Append data to dataframe\n",
    "        out_csv = out_csv.append(dict([('GEO.id2',geo),\n",
    "                                       ('x',x),\n",
    "                                       ('y',y),\n",
    "                                       ('quadkey',quadkey),\n",
    "                                       ('income_category',income_category)]),\n",
    "                                 ignore_index=True)\n",
    "        \n",
    "    for i in range(gt_200k):\n",
    "                \n",
    "        # Choose a random longitude and latitude within the boundary box\n",
    "        # and within the orginial ploygon of the census block\n",
    "\n",
    "        while True:\n",
    "\n",
    "            samplepoint = Point(uniform(leftmost, rightmost),uniform(bottommost, topmost))\n",
    "\n",
    "            if samplepoint is None:\n",
    "                break\n",
    "\n",
    "            if poly.contains(samplepoint):\n",
    "                break\n",
    "\n",
    "        # Convert the longitude and latitude coordinates to meters and\n",
    "        # a tile reference\n",
    "\n",
    "        x, y = merc.LatLonToMeters(samplepoint.y,samplepoint.x)\n",
    "        tx,ty = merc.MetersToTile(x, y, 21)\n",
    "\n",
    "        # Create a unique quadkey for each point object\n",
    "                \n",
    "        quadkey = merc.QuadTree(tx, ty, 21)\n",
    "\n",
    "        # Create categorical variable for the income category\n",
    "\n",
    "        income_category = 'HD01_VD17'         \n",
    "\n",
    "        # Append data to dataframe\n",
    "        out_csv = out_csv.append(dict([('GEO.id2',geo),\n",
    "                                       ('x',x),\n",
    "                                       ('y',y),\n",
    "                                       ('quadkey',quadkey),\n",
    "                                       ('income_category',income_category)]),\n",
    "                                 ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not going to run the above code because\n",
    "\n",
    "    1) I already have, and\n",
    "    2) It took about 3 hours\n",
    "    \n",
    "I do plan on coming back to this on a later post and examining how I couldve generated all of these random coordinates faster and cleaner, but that will have to wait. I really want to see this map!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, export this dataframe to a .csv for further use (and to avoid running that code again...), and we have created our dataset! Now, we just need to get the appropriate visualization libraries and we can see it in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_csv.to_csv(\"censusBlock_incomePoints.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "That's it for this post! If you have any comments, questions, or you just want to get in touch, please email me at `codebycandlelight@gmail.com`. I hope to hear from some of you! See you next time!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
